{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/Smartbuilding/blob/main/1_Experiments_for_University_Dormitory_Building_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSqrEpHafgnJ"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XklPTg0vfgnL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url_univdorm= 'https://raw.githubusercontent.com/irenekarijadi/RF-LSTM-CEEMDAN/main/Dataset/data%20of%20UnivDorm_Prince.csv'\n",
        "univdorm= pd.read_csv(url_univdorm)\n",
        "data_univdorm= univdorm[(univdorm['timestamp'] > '2015-03-01') & (univdorm['timestamp'] < '2015-06-01')]\n",
        "dfs_univdorm=data_univdorm['energy']\n",
        "datas_univdorm=pd.DataFrame(dfs_univdorm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhdgGStjfgnM"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import warnings\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "Si7oUPClgBFE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install EMD-signal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VwzD0YkgR5s",
        "outputId": "e0c48d1a-2b87-4b44-b764-ccc4ca789064"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: EMD-signal in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.10.1)\n",
            "Requirement already satisfied: pathos>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (0.3.0)\n",
            "Requirement already satisfied: tqdm==4.64.* in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (4.64.1)\n",
            "Requirement already satisfied: ppft>=1.7.6.6 in /usr/local/lib/python3.10/dist-packages (from pathos>=0.2.1->EMD-signal) (1.7.6.6)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from pathos>=0.2.1->EMD-signal) (0.3.6)\n",
            "Requirement already satisfied: pox>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from pathos>=0.2.1->EMD-signal) (0.3.2)\n",
            "Requirement already satisfied: multiprocess>=0.70.14 in /usr/local/lib/python3.10/dist-packages (from pathos>=0.2.1->EMD-signal) (0.70.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyEMD import CEEMDAN"
      ],
      "metadata": {
        "id": "8XBdEMXigD5c"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-ny_zInQfgnM"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter('ignore')\n",
        "\n",
        "import numpy\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn import metrics\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dataframe_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y2zobEeiFqS",
        "outputId": "34b0be5b-6966-40c8-ae7f-8d5ee77ed33e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dataframe_image in /usr/local/lib/python3.10/dist-packages (0.1.11)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (1.5.3)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (6.5.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (8.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (23.1)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (0.8.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (4.11.2)\n",
            "Requirement already satisfied: cssutils in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (2.7.1)\n",
            "Requirement already satisfied: html2image in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (2.0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (2.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.8.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.9.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (1.5.0)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (2.14.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (1.2.1)\n",
            "Requirement already satisfied: traitlets>=5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (1.22.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->dataframe_image) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (3.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert>=5->dataframe_image) (3.8.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert>=5->dataframe_image) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert>=5->dataframe_image) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert>=5->dataframe_image) (4.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24->dataframe_image) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->dataframe_image) (0.5.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert>=5->dataframe_image) (0.19.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (23.2.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (6.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dataframe_image as dfi"
      ],
      "metadata": {
        "id": "CRPP8RBKiL2S"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5archLmfgnM"
      },
      "source": [
        "## Import all functions from another notebook for building prediction methods"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "#Parameters Settings\n",
        "\n",
        "max_features=8 # the feature number of each node is set to 8, as it is suggested to be one-third of the feature's number (Lahouar and Slama,2017)\n",
        "lr=0.001 #learning rate LSTM as recommended in (Kingma and Ba, 2014)\n",
        "optimizer='Adam' #Adam is used as the optimizer for LSTM as it is computationally efficient (Dubey, Ashutosh Kumar, et al,2021)\n",
        "neuron=64\n",
        "epoch=100 #(Jorges et al, 2021)\n",
        "batch_size=64 #(Kandel et al,2020)\n",
        "n_hours=24 #in this study, to predict one hour ahead predicton, we use input from the previous 24 hour energy consumption\n",
        "data_partition=0.8 #in this study, we divided the data into 80% of data as training data and 20% of the data as testing data"
      ],
      "metadata": {
        "id": "bK4BzjJZmaJ8"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PyEMD import CEEMDAN\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "### import the libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "def percentage_error(actual, predicted):\n",
        "    res = numpy.empty(actual.shape)\n",
        "    for j in range(actual.shape[0]):\n",
        "        if actual[j] != 0:\n",
        "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
        "        else:\n",
        "            res[j] = predicted[j] / np.mean(actual)\n",
        "    return res\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n",
        "\n",
        "\n",
        "\n",
        "# In[25]:\n",
        "\n",
        "\n",
        "def lr_model(datass,look_back,data_partition):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "    import tensorflow as tf\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "\n",
        "    grid = LinearRegression()\n",
        "\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_lr= grid.predict(X)\n",
        "    y_pred_test_lr= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_lr=pd.DataFrame(y_pred_train_lr)\n",
        "    y_pred_test_lr=pd.DataFrame(y_pred_test_lr)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)\n",
        "    y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)\n",
        "    y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_lr)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_lr))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_lr)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[26]:\n",
        "\n",
        "\n",
        "def svr_model(datass,look_back,data_partition):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "    from sklearn.svm import SVR\n",
        "\n",
        "    grid = SVR()\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_svr= grid.predict(X)\n",
        "    y_pred_test_svr= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_svr=pd.DataFrame(y_pred_train_svr)\n",
        "    y_pred_test_svr=pd.DataFrame(y_pred_test_svr)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)\n",
        "    y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_svr=pd.DataFrame(y_pred_test1_svr)\n",
        "    y_pred_train1_svr=pd.DataFrame(y_pred_train1_svr)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_svr)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_svr))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_svr)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[27]:\n",
        "\n",
        "\n",
        "\n",
        "def ann_model(datass,look_back,data_partition):\n",
        "\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    import numpy\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "    from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "    model= MLPRegressor(random_state=1,activation='tanh').fit(X,y)\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "    # make predictions\n",
        "    y_pred_train = model.predict(X)\n",
        "    y_pred_test = model.predict(X1)\n",
        "    y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "\n",
        "    y_pred_test=pd.DataFrame(y_pred_test)\n",
        "    y1=pd.DataFrame(y1)\n",
        "\n",
        "    y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[28]:\n",
        "\n",
        "\n",
        "def rf_model(datass,look_back,data_partition,max_features):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "    grid = RandomForestRegressor(max_features=max_features)\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_rf= grid.predict(X)\n",
        "    y_pred_test_rf= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_rf=pd.DataFrame(y_pred_train_rf)\n",
        "    y_pred_test_rf=pd.DataFrame(y_pred_test_rf)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_rf= sc_y.inverse_transform (y_pred_test_rf)\n",
        "    y_pred_train1_rf=sc_y.inverse_transform (y_pred_train_rf)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_rf=pd.DataFrame(y_pred_test1_rf)\n",
        "    y_pred_train1_rf=pd.DataFrame(y_pred_train1_rf)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_rf)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_rf))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_rf)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "\n",
        "def lstm_model(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "    trainX1 = numpy.reshape(X, (X.shape[0],1,X.shape[1]))\n",
        "    testX1 = numpy.reshape(X1, (X1.shape[0],1,X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    import os\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers.core import Dense, Dropout, Activation\n",
        "    from keras.layers import LSTM\n",
        "\n",
        "\n",
        "    neuron=neuron\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units = neuron,input_shape=(trainX1.shape[1], trainX1.shape[2])))\n",
        "    model.add(Dense(1))\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(loss='mse',optimizer=optimizer)\n",
        "#    model.summary()\n",
        "\n",
        "\n",
        "  # Fitting the RNN to the Training s\n",
        "    model.fit(trainX1, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "  # make predictions\n",
        "    y_pred_train = model.predict(trainX1)\n",
        "    y_pred_test = model.predict(testX1)\n",
        "    y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "\n",
        "    y_pred_test=pd.DataFrame(y_pred_test)\n",
        "    y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "    y1=pd.DataFrame(y1)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "    from sklearn import metrics\n",
        "\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1)\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "###################################################hybrid based ceemdan####################################################\n",
        "def hybrid_ceemdan_rf(datass,look_back,data_partition,max_features):\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    for col in data_imf:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[col])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "        grid = RandomForestRegressor(max_features=max_features)\n",
        "        grid.fit(X,y)\n",
        "        y_pred_train= grid.predict(X)\n",
        "        y_pred_test= grid.predict(X1)\n",
        "\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "\n",
        "def hybrid_ceemdan_lstm(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "\n",
        "\n",
        "    from PyEMD import CEEMDAN\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    for col in data_imf:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[col])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers.core import Dense, Dropout, Activation\n",
        "        from keras.layers import LSTM\n",
        "\n",
        "\n",
        "        neuron=neuron\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "        model.add(Dense(1))\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        model.compile(loss='mse',optimizer=optimizer)\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "        # Fitting the RNN to the Training set\n",
        "        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "\n",
        "        # make predictions\n",
        "        y_pred_train = model.predict(trainX)\n",
        "        y_pred_test = model.predict(testX)\n",
        "\n",
        "        # make predictions\n",
        "\n",
        "        y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "        y_pred_train= numpy.array(y_pred_train).ravel()\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "def proposed_method(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "\n",
        "    from PyEMD import CEEMDAN\n",
        "\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    n_imf=len(data_imf.columns)\n",
        "\n",
        "    k=list(range(1,n_imf))\n",
        "    m=[0]\n",
        "\n",
        "\n",
        "    for i in m:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[i])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "        grid = RandomForestRegressor(max_features=max_features)\n",
        "        grid.fit(X,y)\n",
        "        y_pred_train= grid.predict(X)\n",
        "        y_pred_test= grid.predict(X1)\n",
        "\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in k:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[i])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers.core import Dense, Dropout, Activation\n",
        "        from keras.layers import LSTM\n",
        "\n",
        "        neuron=neuron\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "        model.add(Dense(1))\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        model.compile(loss='mse',optimizer=optimizer)\n",
        "\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "     # Fitting the RNN to the Training set\n",
        "        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "\n",
        "\n",
        "        # make predictions\n",
        "        y_pred_train = model.predict(trainX)\n",
        "        y_pred_test = model.predict(testX)\n",
        "\n",
        "        # make predictions\n",
        "\n",
        "\n",
        "        y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "        y_pred_train= numpy.array(y_pred_train).ravel()\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "    return mape,rmse,mae,a,y_test\n"
      ],
      "metadata": {
        "id": "TzduYmntmwj7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8ju1llJfgnN"
      },
      "source": [
        "## Import parameter settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_features=8 # the feature number of each node is set to 8, as it is suggested to be one-third of the feature's number (Lahouar and Slama,2017)\n",
        "lr=0.001 #learning rate LSTM as recommended in (Kingma and Ba, 2014)\n",
        "optimizer='Adam' #Adam is used as the optimizer for LSTM as it is computationally efficient (Dubey, Ashutosh Kumar, et al,2021)\n",
        "neuron=64\n",
        "epoch=100 #(Jorges et al, 2021)\n",
        "batch_size=64 #(Kandel et al,2020)\n",
        "hours=24 #in this study, to predict one hour ahead predicton, we use input from the previous 24 hour energy consumption\n",
        "data_partition=0.8 #in this study, we divided the data into 80% of data as training data and 20% of the data as testing data"
      ],
      "metadata": {
        "id": "_abXl6B6nVMd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwFutNkWfgnN"
      },
      "source": [
        "## Run the experiments\n",
        "### Run this following cell will train and test the proposed method and other benchmark methods on University Dormitory Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoBT7K_5oP-Y",
        "outputId": "653e7cdc-6468-453b-d7eb-7c8f4257f1d4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM"
      ],
      "metadata": {
        "id": "zuHWMkP1qCGi"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaTyglZ2fgnN",
        "outputId": "3677b97b-1cba-42c1-eba2-b8dccd3ccdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 0.13720488548278809 seconds - Linear Regression- univdorm ---\n",
            "--- 1.2177515029907227 seconds - Support Vector Regression- univdorm ---\n",
            "--- 4.076772451400757 seconds - ANN- univdorm ---\n",
            "--- 1.3644065856933594 seconds - Random Forest- univdorm ---\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "--- 12.78627634048462 seconds - lstm- univdorm ---\n",
            "--- 46.89029669761658 seconds - ceemdan_rf- univdorm ---\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 3ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 3ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "--- 141.1579830646515 seconds - ceemdan_lstm- univdorm ---\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 3ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "--- 132.06445050239563 seconds - proposed_method- univdorm ---\n"
          ]
        }
      ],
      "source": [
        "#Linear Regression\n",
        "\n",
        "start_time = time.time()\n",
        "lr_univdorm=lr_model(datas_univdorm,hours,data_partition)\n",
        "lr_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - Linear Regression- univdorm ---\" % (lr_time_univdorm))\n",
        "\n",
        "#Support Vector Regression\n",
        "start_time = time.time()\n",
        "svr_univdorm=svr_model(datas_univdorm,hours,data_partition)\n",
        "svr_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - Support Vector Regression- univdorm ---\" % (svr_time_univdorm))\n",
        "\n",
        "\n",
        "#ANN\n",
        "start_time = time.time()\n",
        "ann_univdorm=ann_model(datas_univdorm,hours,data_partition)\n",
        "ann_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - ANN- univdorm ---\" % (ann_time_univdorm))\n",
        "\n",
        "#random forest\n",
        "start_time = time.time()\n",
        "rf_univdorm=rf_model(datas_univdorm,hours,data_partition,max_features)\n",
        "rf_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - Random Forest- univdorm ---\" % (rf_time_univdorm))\n",
        "\n",
        "#LSTM\n",
        "start_time = time.time()\n",
        "lstm_univdorm=lstm_model(datas_univdorm,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "lstm_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - lstm- univdorm ---\" % (lstm_time_univdorm))\n",
        "\n",
        "\n",
        "#CEEMDAN RF\n",
        "start_time = time.time()\n",
        "ceemdan_rf_univdorm=hybrid_ceemdan_rf(dfs_univdorm,hours,data_partition,max_features)\n",
        "ceemdan_rf_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - ceemdan_rf- univdorm ---\" % (ceemdan_rf_time_univdorm))\n",
        "\n",
        "#CEEMDAN LSTM\n",
        "start_time = time.time()\n",
        "ceemdan_lstm_univdorm=hybrid_ceemdan_lstm(dfs_univdorm,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "ceemdan_lstm_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - ceemdan_lstm- univdorm ---\" % (ceemdan_lstm_time_univdorm))\n",
        "\n",
        "\n",
        "#proposed method\n",
        "start_time = time.time()\n",
        "proposed_method_univdorm=proposed_method(dfs_univdorm,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "proposed_method_time_univdorm=time.time() - start_time\n",
        "print(\"--- %s seconds - proposed_method- univdorm ---\" % (proposed_method_time_univdorm))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "943bnd1lfgnO"
      },
      "source": [
        "## Summarize of experimental results with running time\n",
        "### Run this following cell will summarize the result and generate output used in Section 4.4 (Table 3) for University Dormitory dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vcgjqhCAfgnO",
        "outputId": "d5cd6513-894e-4587-cb49-aa1952e87aba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    LR       SVR       ANN        RF  \\\n",
              "university dormitory results                                           \n",
              "0                             6.096747  6.486764  6.719073  6.153492   \n",
              "1                             3.091409  3.386055  3.389476  3.194408   \n",
              "2                             2.401101  2.590120  2.640636  2.440198   \n",
              "0                             0.137205  1.217752  4.076772  1.364407   \n",
              "\n",
              "                                   LSTM  CEEMDAN RF  CEEMDAN LSTM  \\\n",
              "university dormitory results                                        \n",
              "0                              7.027999    3.950790      4.146746   \n",
              "1                              3.504771    2.004695      2.107329   \n",
              "2                              2.752118    1.545388      1.617382   \n",
              "0                             12.786276   46.890297    141.157983   \n",
              "\n",
              "                              Proposed Method  \n",
              "university dormitory results                   \n",
              "0                                    3.495062  \n",
              "1                                    1.761992  \n",
              "2                                    1.362670  \n",
              "0                                  132.064451  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c5284db4-fc2a-4edd-88c3-01070c466b47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LR</th>\n",
              "      <th>SVR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>CEEMDAN RF</th>\n",
              "      <th>CEEMDAN LSTM</th>\n",
              "      <th>Proposed Method</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>university dormitory results</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.096747</td>\n",
              "      <td>6.486764</td>\n",
              "      <td>6.719073</td>\n",
              "      <td>6.153492</td>\n",
              "      <td>7.027999</td>\n",
              "      <td>3.950790</td>\n",
              "      <td>4.146746</td>\n",
              "      <td>3.495062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.091409</td>\n",
              "      <td>3.386055</td>\n",
              "      <td>3.389476</td>\n",
              "      <td>3.194408</td>\n",
              "      <td>3.504771</td>\n",
              "      <td>2.004695</td>\n",
              "      <td>2.107329</td>\n",
              "      <td>1.761992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.401101</td>\n",
              "      <td>2.590120</td>\n",
              "      <td>2.640636</td>\n",
              "      <td>2.440198</td>\n",
              "      <td>2.752118</td>\n",
              "      <td>1.545388</td>\n",
              "      <td>1.617382</td>\n",
              "      <td>1.362670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.137205</td>\n",
              "      <td>1.217752</td>\n",
              "      <td>4.076772</td>\n",
              "      <td>1.364407</td>\n",
              "      <td>12.786276</td>\n",
              "      <td>46.890297</td>\n",
              "      <td>141.157983</td>\n",
              "      <td>132.064451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5284db4-fc2a-4edd-88c3-01070c466b47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-acf56f86-adce-4139-bcf6-29142534a727\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acf56f86-adce-4139-bcf6-29142534a727')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-acf56f86-adce-4139-bcf6-29142534a727 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5284db4-fc2a-4edd-88c3-01070c466b47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5284db4-fc2a-4edd-88c3-01070c466b47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "running_time_univdorm=pd.DataFrame([lr_time_univdorm,svr_time_univdorm,ann_time_univdorm,\n",
        "                                   rf_time_univdorm,lstm_time_univdorm,ceemdan_rf_time_univdorm,\n",
        "                                   ceemdan_lstm_time_univdorm,proposed_method_time_univdorm])\n",
        "running_time_univdorm=running_time_univdorm.T\n",
        "running_time_univdorm.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method']\n",
        "proposed_method_univdorm_df=proposed_method_univdorm[0:3]\n",
        "result_univdorm=pd.DataFrame([lr_univdorm,svr_univdorm,ann_univdorm,rf_univdorm,lstm_univdorm,ceemdan_rf_univdorm,\n",
        "                    ceemdan_lstm_univdorm,proposed_method_univdorm_df])\n",
        "result_univdorm=result_univdorm.T\n",
        "result_univdorm.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method']\n",
        "univdorm_summary=pd.concat([result_univdorm,running_time_univdorm],axis=0)\n",
        "\n",
        "univdorm_summary.set_axis(['MAPE(%)', 'RMSE','MAE','running time (s)'], axis='index')\n",
        "\n",
        "univdorm_summary.style.set_caption(\"University Dormitory Results\")\n",
        "index = univdorm_summary.index\n",
        "index.name = \"university dormitory results\"\n",
        "univdorm_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8exM3QKfgnO"
      },
      "outputs": [],
      "source": [
        "#export table to png\n",
        "#dfi.export(univdorm_summary,\"univdorm_summary_table.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpeUgzM2fgnP"
      },
      "source": [
        "## Calculate percentage improvement\n",
        "### Run this following cell will calculate percentage improvement and generate output used in Section 4.4 (Table 4) for University Dormitory dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "z-nkBOLZfgnP",
        "outputId": "e484a058-7271-4fa9-90e0-845307a14192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Proposed Method vs.LR  \\\n",
              "Percentage Improvement university dormitory                          \n",
              "0                                                            42.67   \n",
              "1                                                            43.00   \n",
              "2                                                            43.25   \n",
              "\n",
              "                                             Proposed Method vs.SVR  \\\n",
              "Percentage Improvement university dormitory                           \n",
              "0                                                             46.12   \n",
              "1                                                             47.96   \n",
              "2                                                             47.39   \n",
              "\n",
              "                                              Proposed Method vs.ANN  \\\n",
              "Percentage Improvement university dormitory                            \n",
              "0                                                              47.98   \n",
              "1                                                              48.02   \n",
              "2                                                              48.40   \n",
              "\n",
              "                                             Proposed Method vs.RF  \\\n",
              "Percentage Improvement university dormitory                          \n",
              "0                                                            43.20   \n",
              "1                                                            44.84   \n",
              "2                                                            44.16   \n",
              "\n",
              "                                             Proposed Method vs.LSTM  \\\n",
              "Percentage Improvement university dormitory                            \n",
              "0                                                              50.27   \n",
              "1                                                              49.73   \n",
              "2                                                              50.49   \n",
              "\n",
              "                                             Proposed Method vs.CEEMDAN RF  \\\n",
              "Percentage Improvement university dormitory                                  \n",
              "0                                                                    11.54   \n",
              "1                                                                    12.11   \n",
              "2                                                                    11.82   \n",
              "\n",
              "                                             Proposed Method vs. CEEMDAN LSTM  \n",
              "Percentage Improvement university dormitory                                    \n",
              "0                                                                       15.72  \n",
              "1                                                                       16.39  \n",
              "2                                                                       15.75  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-67ab130c-2858-45e4-922a-59d669ffa71f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Proposed Method vs.LR</th>\n",
              "      <th>Proposed Method vs.SVR</th>\n",
              "      <th>Proposed Method vs.ANN</th>\n",
              "      <th>Proposed Method vs.RF</th>\n",
              "      <th>Proposed Method vs.LSTM</th>\n",
              "      <th>Proposed Method vs.CEEMDAN RF</th>\n",
              "      <th>Proposed Method vs. CEEMDAN LSTM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Percentage Improvement university dormitory</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42.67</td>\n",
              "      <td>46.12</td>\n",
              "      <td>47.98</td>\n",
              "      <td>43.20</td>\n",
              "      <td>50.27</td>\n",
              "      <td>11.54</td>\n",
              "      <td>15.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43.00</td>\n",
              "      <td>47.96</td>\n",
              "      <td>48.02</td>\n",
              "      <td>44.84</td>\n",
              "      <td>49.73</td>\n",
              "      <td>12.11</td>\n",
              "      <td>16.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43.25</td>\n",
              "      <td>47.39</td>\n",
              "      <td>48.40</td>\n",
              "      <td>44.16</td>\n",
              "      <td>50.49</td>\n",
              "      <td>11.82</td>\n",
              "      <td>15.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67ab130c-2858-45e4-922a-59d669ffa71f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-580b3d92-ba6d-451f-9daf-72cebded9adb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-580b3d92-ba6d-451f-9daf-72cebded9adb')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-580b3d92-ba6d-451f-9daf-72cebded9adb button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67ab130c-2858-45e4-922a-59d669ffa71f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67ab130c-2858-45e4-922a-59d669ffa71f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "pMAPE_LR_vs_Proposed_univdorm=((lr_univdorm[0]-proposed_method_univdorm[0])/lr_univdorm[0])*100\n",
        "pRMSE_LR_vs_Proposed_univdorm=((lr_univdorm[1]-proposed_method_univdorm[1])/lr_univdorm[1])*100\n",
        "pMAE_LR_vs_Proposed_univdorm=((lr_univdorm[2]-proposed_method_univdorm[2])/lr_univdorm[2])*100\n",
        "\n",
        "pMAPE_SVR_vs_Proposed_univdorm=((svr_univdorm[0]-proposed_method_univdorm[0])/svr_univdorm[0])*100\n",
        "pRMSE_SVR_vs_Proposed_univdorm=((svr_univdorm[1]-proposed_method_univdorm[1])/svr_univdorm[1])*100\n",
        "pMAE_SVR_vs_Proposed_univdorm=((svr_univdorm[2]-proposed_method_univdorm[2])/svr_univdorm[2])*100\n",
        "\n",
        "pMAPE_ANN_vs_Proposed_univdorm=((ann_univdorm[0]-proposed_method_univdorm[0])/ann_univdorm[0])*100\n",
        "pRMSE_ANN_vs_Proposed_univdorm=((ann_univdorm[1]-proposed_method_univdorm[1])/ann_univdorm[1])*100\n",
        "pMAE_ANN_vs_Proposed_univdorm=((ann_univdorm[2]-proposed_method_univdorm[2])/ann_univdorm[2])*100\n",
        "\n",
        "pMAPE_RF_vs_Proposed_univdorm=((rf_univdorm[0]-proposed_method_univdorm[0])/rf_univdorm[0])*100\n",
        "pRMSE_RF_vs_Proposed_univdorm=((rf_univdorm[1]-proposed_method_univdorm[1])/rf_univdorm[1])*100\n",
        "pMAE_RF_vs_Proposed_univdorm=((rf_univdorm[2]-proposed_method_univdorm[2])/rf_univdorm[2])*100\n",
        "\n",
        "pMAPE_LSTM_vs_Proposed_univdorm=((lstm_univdorm[0]-proposed_method_univdorm[0])/lstm_univdorm[0])*100\n",
        "pRMSE_LSTM_vs_Proposed_univdorm=((lstm_univdorm[1]-proposed_method_univdorm[1])/lstm_univdorm[1])*100\n",
        "pMAE_LSTM_vs_Proposed_univdorm=((lstm_univdorm[2]-proposed_method_univdorm[2])/lstm_univdorm[2])*100\n",
        "\n",
        "pMAPE_ceemdan_rf_vs_Proposed_univdorm=((ceemdan_rf_univdorm[0]-proposed_method_univdorm[0])/ceemdan_rf_univdorm[0])*100\n",
        "pRMSE_ceemdan_rf_vs_Proposed_univdorm=((ceemdan_rf_univdorm[1]-proposed_method_univdorm[1])/ceemdan_rf_univdorm[1])*100\n",
        "pMAE_ceemdan_rf_vs_Proposed_univdorm=((ceemdan_rf_univdorm[2]-proposed_method_univdorm[2])/ceemdan_rf_univdorm[2])*100\n",
        "\n",
        "\n",
        "pMAPE_ceemdan_lstm_vs_Proposed_univdorm=((ceemdan_lstm_univdorm[0]-proposed_method_univdorm[0])/ceemdan_lstm_univdorm[0])*100\n",
        "pRMSE_ceemdan_lstm_vs_Proposed_univdorm=((ceemdan_lstm_univdorm[1]-proposed_method_univdorm[1])/ceemdan_lstm_univdorm[1])*100\n",
        "pMAE_ceemdan_lstm_vs_Proposed_univdorm=((ceemdan_lstm_univdorm[2]-proposed_method_univdorm[2])/ceemdan_lstm_univdorm[2])*100\n",
        "\n",
        "\n",
        "df_PI_univdorm=[[pMAPE_LR_vs_Proposed_univdorm,pMAPE_SVR_vs_Proposed_univdorm,pMAPE_ANN_vs_Proposed_univdorm,\n",
        "                pMAPE_RF_vs_Proposed_univdorm,pMAPE_LSTM_vs_Proposed_univdorm,pMAPE_ceemdan_rf_vs_Proposed_univdorm,\n",
        "                pMAPE_ceemdan_lstm_vs_Proposed_univdorm],\n",
        "                [pRMSE_LR_vs_Proposed_univdorm,pRMSE_SVR_vs_Proposed_univdorm,pRMSE_ANN_vs_Proposed_univdorm,\n",
        "                pRMSE_RF_vs_Proposed_univdorm,pRMSE_LSTM_vs_Proposed_univdorm,pRMSE_ceemdan_rf_vs_Proposed_univdorm,\n",
        "                pRMSE_ceemdan_lstm_vs_Proposed_univdorm],\n",
        "                [pMAE_LR_vs_Proposed_univdorm,pMAE_SVR_vs_Proposed_univdorm,pMAE_ANN_vs_Proposed_univdorm,\n",
        "                pMAE_RF_vs_Proposed_univdorm,pMAE_LSTM_vs_Proposed_univdorm,pMAE_ceemdan_rf_vs_Proposed_univdorm,\n",
        "                pMAE_ceemdan_lstm_vs_Proposed_univdorm]]\n",
        "\n",
        "PI_univdorm=pd.DataFrame(df_PI_univdorm, columns=[\"Proposed Method vs.LR\", \"Proposed Method vs.SVR\",\" Proposed Method vs.ANN\",\n",
        "                                      \"Proposed Method vs.RF\",\"Proposed Method vs.LSTM\",\"Proposed Method vs.CEEMDAN RF\",\n",
        "                                      \"Proposed Method vs. CEEMDAN LSTM\"])\n",
        "PI_univdorm= PI_univdorm.round(decimals = 2)\n",
        "PI_univdorm.set_axis(['MAPE(%)', 'RMSE','MAE'], axis='index')\n",
        "PI_univdorm.style.set_caption(\"Percentage Improvement-University Dormitory Building\")\n",
        "index = PI_univdorm.index\n",
        "index.name = \"Percentage Improvement university dormitory\"\n",
        "PI_univdorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpRbTb_WfgnP"
      },
      "outputs": [],
      "source": [
        "#export table to png\n",
        "#dfi.export(PI_univdorm,\"PI_univdorm_table.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKgyjEvXfgnP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}