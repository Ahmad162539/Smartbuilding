{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/Smartbuilding/blob/main/University_Classroom_Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBRJJG0eZ5W7"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "740JzcdIZ5W9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url_univclass= 'https://raw.githubusercontent.com/Ahmad162539/Smartbuilding/main/data%20of%20UnivClass_Abby.csv'\n",
        "univclass= pd.read_csv(url_univclass)\n",
        "data_univclass= univclass[(univclass['timestamp'] > '2015-03-01') & (univclass['timestamp'] < '2015-06-01')]\n",
        "dfs_univclass=data_univclass['energy']\n",
        "datas_univclass=pd.DataFrame(dfs_univclass)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy8OPoF9Z5W9"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P1fn6BScZ5W-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter('ignore')\n",
        "\n",
        "import numpy\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn import metrics\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install EMD-signal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC81-5VPaI9e",
        "outputId": "14b6f38e-a20f-4adc-ad9c-f2c398386c50"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting EMD-signal\n",
            "  Downloading EMD_signal-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.10.1)\n",
            "Collecting pathos>=0.2.1 (from EMD-signal)\n",
            "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.* (from EMD-signal)\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ppft>=1.7.6.6 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.6 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.2 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.14 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, ppft, pox, dill, multiprocess, pathos, EMD-signal\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "Successfully installed EMD-signal-1.5.1 dill-0.3.6 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 tqdm-4.64.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyEMD import CEEMDAN"
      ],
      "metadata": {
        "id": "WHUW358maPC-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dataframe_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SclgtOxxaR5N",
        "outputId": "8ad3dcbe-1d24-41f0-ca75-b12c4c8bee49"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataframe_image\n",
            "  Downloading dataframe_image-0.1.11-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (1.5.3)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (6.5.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (8.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (23.1)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (0.8.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (4.11.2)\n",
            "Collecting cssutils (from dataframe_image)\n",
            "  Downloading cssutils-2.7.1-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2image (from dataframe_image)\n",
            "  Downloading html2image-2.0.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (2.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.8.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.9.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (1.5.0)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (2.14.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (1.2.1)\n",
            "Requirement already satisfied: traitlets>=5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (1.22.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->dataframe_image) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (3.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert>=5->dataframe_image) (3.8.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert>=5->dataframe_image) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert>=5->dataframe_image) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert>=5->dataframe_image) (4.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24->dataframe_image) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->dataframe_image) (0.5.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert>=5->dataframe_image) (0.19.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (23.2.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (6.3.1)\n",
            "Installing collected packages: html2image, cssutils, dataframe_image\n",
            "Successfully installed cssutils-2.7.1 dataframe_image-0.1.11 html2image-2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dataframe_image as dfi"
      ],
      "metadata": {
        "id": "hYktsvFeaUwn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uu7OX5OZ5W-"
      },
      "source": [
        "## Import all functions from another notebook for building prediction methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "afxDzItDZ5W-"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "#Parameters Settings\n",
        "\n",
        "max_features=8 # the feature number of each node is set to 8, as it is suggested to be one-third of the feature's number (Lahouar and Slama,2017)\n",
        "lr=0.001 #learning rate LSTM as recommended in (Kingma and Ba, 2014)\n",
        "optimizer='Adam' #Adam is used as the optimizer for LSTM as it is computationally efficient (Dubey, Ashutosh Kumar, et al,2021)\n",
        "neuron=64\n",
        "epoch=100 #(Jorges et al, 2021)\n",
        "batch_size=64 #(Kandel et al,2020)\n",
        "hours=24 #in this study, to predict one hour ahead predicton, we use input from the previous 24 hour energy consumption\n",
        "data_partition=0.8 #in this study, we divided the data into 80% of data as training data and 20% of the data as testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqNxj1GQZ5W-"
      },
      "source": [
        "## Import parameter settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SpPrjaX6Z5W-"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PyEMD import CEEMDAN\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "### import the libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "def percentage_error(actual, predicted):\n",
        "    res = numpy.empty(actual.shape)\n",
        "    for j in range(actual.shape[0]):\n",
        "        if actual[j] != 0:\n",
        "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
        "        else:\n",
        "            res[j] = predicted[j] / np.mean(actual)\n",
        "    return res\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n",
        "\n",
        "\n",
        "\n",
        "# In[25]:\n",
        "\n",
        "\n",
        "def lr_model(datass,look_back,data_partition):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "    import tensorflow as tf\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "\n",
        "    grid = LinearRegression()\n",
        "\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_lr= grid.predict(X)\n",
        "    y_pred_test_lr= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_lr=pd.DataFrame(y_pred_train_lr)\n",
        "    y_pred_test_lr=pd.DataFrame(y_pred_test_lr)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)\n",
        "    y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)\n",
        "    y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_lr)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_lr))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_lr)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[26]:\n",
        "\n",
        "\n",
        "def svr_model(datass,look_back,data_partition):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "    from sklearn.svm import SVR\n",
        "\n",
        "    grid = SVR()\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_svr= grid.predict(X)\n",
        "    y_pred_test_svr= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_svr=pd.DataFrame(y_pred_train_svr)\n",
        "    y_pred_test_svr=pd.DataFrame(y_pred_test_svr)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)\n",
        "    y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_svr=pd.DataFrame(y_pred_test1_svr)\n",
        "    y_pred_train1_svr=pd.DataFrame(y_pred_train1_svr)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_svr)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_svr))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_svr)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[27]:\n",
        "\n",
        "\n",
        "\n",
        "def ann_model(datass,look_back,data_partition):\n",
        "\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    import numpy\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "    from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "    model= MLPRegressor(random_state=1,activation='tanh').fit(X,y)\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "    # make predictions\n",
        "    y_pred_train = model.predict(X)\n",
        "    y_pred_test = model.predict(X1)\n",
        "    y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "\n",
        "    y_pred_test=pd.DataFrame(y_pred_test)\n",
        "    y1=pd.DataFrame(y1)\n",
        "\n",
        "    y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[28]:\n",
        "\n",
        "\n",
        "def rf_model(datass,look_back,data_partition,max_features):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "    grid = RandomForestRegressor(max_features=max_features)\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_rf= grid.predict(X)\n",
        "    y_pred_test_rf= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_rf=pd.DataFrame(y_pred_train_rf)\n",
        "    y_pred_test_rf=pd.DataFrame(y_pred_test_rf)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_rf= sc_y.inverse_transform (y_pred_test_rf)\n",
        "    y_pred_train1_rf=sc_y.inverse_transform (y_pred_train_rf)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_rf=pd.DataFrame(y_pred_test1_rf)\n",
        "    y_pred_train1_rf=pd.DataFrame(y_pred_train1_rf)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_rf)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_rf))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_rf)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "\n",
        "def lstm_model(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "    trainX1 = numpy.reshape(X, (X.shape[0],1,X.shape[1]))\n",
        "    testX1 = numpy.reshape(X1, (X1.shape[0],1,X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    import os\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers.core import Dense, Dropout, Activation\n",
        "    from keras.layers import LSTM\n",
        "\n",
        "\n",
        "    neuron=neuron\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units = neuron,input_shape=(trainX1.shape[1], trainX1.shape[2])))\n",
        "    model.add(Dense(1))\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(loss='mse',optimizer=optimizer)\n",
        "#    model.summary()\n",
        "\n",
        "\n",
        "  # Fitting the RNN to the Training s\n",
        "    model.fit(trainX1, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "  # make predictions\n",
        "    y_pred_train = model.predict(trainX1)\n",
        "    y_pred_test = model.predict(testX1)\n",
        "    y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "\n",
        "    y_pred_test=pd.DataFrame(y_pred_test)\n",
        "    y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "    y1=pd.DataFrame(y1)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "    from sklearn import metrics\n",
        "\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1)\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "###################################################hybrid based ceemdan####################################################\n",
        "def hybrid_ceemdan_rf(datass,look_back,data_partition,max_features):\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    for col in data_imf:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[col])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "        grid = RandomForestRegressor(max_features=max_features)\n",
        "        grid.fit(X,y)\n",
        "        y_pred_train= grid.predict(X)\n",
        "        y_pred_test= grid.predict(X1)\n",
        "\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "\n",
        "def hybrid_ceemdan_lstm(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "\n",
        "\n",
        "    from PyEMD import CEEMDAN\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    for col in data_imf:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[col])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers.core import Dense, Dropout, Activation\n",
        "        from keras.layers import LSTM\n",
        "\n",
        "\n",
        "        neuron=neuron\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "        model.add(Dense(1))\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        model.compile(loss='mse',optimizer=optimizer)\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "        # Fitting the RNN to the Training set\n",
        "        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "\n",
        "        # make predictions\n",
        "        y_pred_train = model.predict(trainX)\n",
        "        y_pred_test = model.predict(testX)\n",
        "\n",
        "        # make predictions\n",
        "\n",
        "        y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "        y_pred_train= numpy.array(y_pred_train).ravel()\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "def proposed_method(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "\n",
        "    from PyEMD import CEEMDAN\n",
        "\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    n_imf=len(data_imf.columns)\n",
        "\n",
        "    k=list(range(1,n_imf))\n",
        "    m=[0]\n",
        "\n",
        "\n",
        "    for i in m:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[i])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "        grid = RandomForestRegressor(max_features=max_features)\n",
        "        grid.fit(X,y)\n",
        "        y_pred_train= grid.predict(X)\n",
        "        y_pred_test= grid.predict(X1)\n",
        "\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in k:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[i])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers.core import Dense, Dropout, Activation\n",
        "        from keras.layers import LSTM\n",
        "\n",
        "        neuron=neuron\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "        model.add(Dense(1))\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        model.compile(loss='mse',optimizer=optimizer)\n",
        "\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "     # Fitting the RNN to the Training set\n",
        "        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "\n",
        "\n",
        "        # make predictions\n",
        "        y_pred_train = model.predict(trainX)\n",
        "        y_pred_test = model.predict(testX)\n",
        "\n",
        "        # make predictions\n",
        "\n",
        "\n",
        "        y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "        y_pred_train= numpy.array(y_pred_train).ravel()\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "    return mape,rmse,mae,a,y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnDwQ-MEZ5W-"
      },
      "source": [
        "## Run the experiments\n",
        "### Run this following cell will train and test the proposed method and other benchmark methods on University Classroom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw2tWiPaZ5W-",
        "outputId": "8be8b50b-a79d-4755-bfe1-91a8362e756c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 0.6283760070800781 seconds - Linear Regression- univclass ---\n",
            "--- 2.306138753890991 seconds - Support Vector Regression- univclass ---\n",
            "--- 15.531362771987915 seconds - ANN- univclass ---\n",
            "--- 2.8023970127105713 seconds - Random Forest- univclass ---\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "--- 14.101655006408691 seconds - lstm- univclass ---\n",
            "--- 32.814348459243774 seconds - ceemdan_rf- univclass ---\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 3ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "--- 136.00034379959106 seconds - ceemdan_lstm- univclass ---\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 1s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "--- 123.12591171264648 seconds - proposed_method- univclass ---\n"
          ]
        }
      ],
      "source": [
        "#Linear Regression\n",
        "\n",
        "start_time = time.time()\n",
        "lr_univclass=lr_model(datas_univclass,hours,data_partition)\n",
        "lr_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - Linear Regression- univclass ---\" % (lr_time_univclass))\n",
        "\n",
        "#Support Vector Regression\n",
        "start_time = time.time()\n",
        "svr_univclass=svr_model(datas_univclass,hours,data_partition)\n",
        "svr_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - Support Vector Regression- univclass ---\" % (svr_time_univclass))\n",
        "\n",
        "\n",
        "#ANN\n",
        "start_time = time.time()\n",
        "ann_univclass=ann_model(datas_univclass,hours,data_partition)\n",
        "ann_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - ANN- univclass ---\" % (ann_time_univclass))\n",
        "\n",
        "#random forest\n",
        "start_time = time.time()\n",
        "rf_univclass=rf_model(datas_univclass,hours,data_partition,max_features)\n",
        "rf_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - Random Forest- univclass ---\" % (rf_time_univclass))\n",
        "\n",
        "#LSTM\n",
        "start_time = time.time()\n",
        "lstm_univclass=lstm_model(datas_univclass,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "lstm_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - lstm- univclass ---\" % (lstm_time_univclass))\n",
        "\n",
        "\n",
        "#CEEMDAN RF\n",
        "start_time = time.time()\n",
        "ceemdan_rf_univclass=hybrid_ceemdan_rf(dfs_univclass,hours,data_partition,max_features)\n",
        "ceemdan_rf_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - ceemdan_rf- univclass ---\" % (ceemdan_rf_time_univclass))\n",
        "\n",
        "#CEEMDAN LSTM\n",
        "start_time = time.time()\n",
        "ceemdan_lstm_univclass=hybrid_ceemdan_lstm(dfs_univclass,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "ceemdan_lstm_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - ceemdan_lstm- univclass ---\" % (ceemdan_lstm_time_univclass))\n",
        "\n",
        "\n",
        "#proposed method\n",
        "start_time = time.time()\n",
        "proposed_method_univclass=proposed_method(dfs_univclass,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "proposed_method_time_univclass=time.time() - start_time\n",
        "print(\"--- %s seconds - proposed_method- univclass ---\" % (proposed_method_time_univclass))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYM57yiwZ5W_"
      },
      "source": [
        "## Summarize of experimental results with running time\n",
        "### Run this following cell will summarize the result and generate output used in Section 4.4 (Table 3) for University Classroom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "WO407lepZ5W_",
        "outputId": "98b70fd3-2b6a-44a7-b5bf-501daca02606"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    LR       SVR        ANN        RF  \\\n",
              "University Classroom results                                            \n",
              "0                             3.655593  5.807452   5.983385  7.021900   \n",
              "1                             1.628556  2.529214   2.401744  2.686387   \n",
              "2                             1.061574  1.779553   1.748034  2.079678   \n",
              "0                             0.628376  2.306139  15.531363  2.802397   \n",
              "\n",
              "                                   LSTM  CEEMDAN RF  CEEMDAN LSTM  \\\n",
              "University Classroom results                                        \n",
              "0                              4.997589    3.055443      2.122903   \n",
              "1                              2.102694    1.321730      0.868687   \n",
              "2                              1.469287    0.913354      0.609031   \n",
              "0                             14.101655   32.814348    136.000344   \n",
              "\n",
              "                              Proposed Method  \n",
              "University Classroom results                   \n",
              "0                                    1.994758  \n",
              "1                                    0.837404  \n",
              "2                                    0.579549  \n",
              "0                                  123.125912  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1ddfe690-3a46-4bac-ac70-430ed4db22f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LR</th>\n",
              "      <th>SVR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>CEEMDAN RF</th>\n",
              "      <th>CEEMDAN LSTM</th>\n",
              "      <th>Proposed Method</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>University Classroom results</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.655593</td>\n",
              "      <td>5.807452</td>\n",
              "      <td>5.983385</td>\n",
              "      <td>7.021900</td>\n",
              "      <td>4.997589</td>\n",
              "      <td>3.055443</td>\n",
              "      <td>2.122903</td>\n",
              "      <td>1.994758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.628556</td>\n",
              "      <td>2.529214</td>\n",
              "      <td>2.401744</td>\n",
              "      <td>2.686387</td>\n",
              "      <td>2.102694</td>\n",
              "      <td>1.321730</td>\n",
              "      <td>0.868687</td>\n",
              "      <td>0.837404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.061574</td>\n",
              "      <td>1.779553</td>\n",
              "      <td>1.748034</td>\n",
              "      <td>2.079678</td>\n",
              "      <td>1.469287</td>\n",
              "      <td>0.913354</td>\n",
              "      <td>0.609031</td>\n",
              "      <td>0.579549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.628376</td>\n",
              "      <td>2.306139</td>\n",
              "      <td>15.531363</td>\n",
              "      <td>2.802397</td>\n",
              "      <td>14.101655</td>\n",
              "      <td>32.814348</td>\n",
              "      <td>136.000344</td>\n",
              "      <td>123.125912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ddfe690-3a46-4bac-ac70-430ed4db22f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-ecc2c537-0530-413b-8c06-227fcd8c7c5b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecc2c537-0530-413b-8c06-227fcd8c7c5b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-ecc2c537-0530-413b-8c06-227fcd8c7c5b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ddfe690-3a46-4bac-ac70-430ed4db22f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ddfe690-3a46-4bac-ac70-430ed4db22f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "running_time_univclass=pd.DataFrame([lr_time_univclass,svr_time_univclass,ann_time_univclass,\n",
        "                                   rf_time_univclass,lstm_time_univclass,ceemdan_rf_time_univclass,\n",
        "                                   ceemdan_lstm_time_univclass,proposed_method_time_univclass])\n",
        "running_time_univclass=running_time_univclass.T\n",
        "running_time_univclass.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method']\n",
        "\n",
        "proposed_method_univclass_df=proposed_method_univclass[0:3]\n",
        "result_univclass=pd.DataFrame([lr_univclass,svr_univclass,ann_univclass,rf_univclass,lstm_univclass,ceemdan_rf_univclass,\n",
        "                    ceemdan_lstm_univclass,proposed_method_univclass_df])\n",
        "result_univclass=result_univclass.T\n",
        "result_univclass.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method']\n",
        "univclass_summary=pd.concat([result_univclass,running_time_univclass],axis=0)\n",
        "\n",
        "univclass_summary.set_axis(['MAPE(%)', 'RMSE','MAE','running time (s)'], axis='index')\n",
        "\n",
        "univclass_summary.style.set_caption(\"University Classroom Results\")\n",
        "\n",
        "index = univclass_summary.index\n",
        "index.name =\"University Classroom results\"\n",
        "univclass_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlYz2vu5Z5XA"
      },
      "outputs": [],
      "source": [
        "#export table to png\n",
        "#dfi.export(univclass_summary,\"univclass_summary_table.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUOJlTBZ5XA"
      },
      "source": [
        "## Calculate percentage improvement\n",
        "### Run this following cell will calculate percentage improvement and generate output used in Section 4.4 (Table 4) for University Classroom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "MI9x-K8TZ5XA",
        "outputId": "7db728c5-b371-47b7-e4ce-a126aa860e7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Proposed Method vs.LR  \\\n",
              "Percentage Improvement university classroom                          \n",
              "0                                                            45.43   \n",
              "1                                                            48.58   \n",
              "2                                                            45.41   \n",
              "\n",
              "                                             Proposed Method vs.SVR  \\\n",
              "Percentage Improvement university classroom                           \n",
              "0                                                             65.65   \n",
              "1                                                             66.89   \n",
              "2                                                             67.43   \n",
              "\n",
              "                                              Proposed Method vs.ANN  \\\n",
              "Percentage Improvement university classroom                            \n",
              "0                                                              66.66   \n",
              "1                                                              65.13   \n",
              "2                                                              66.85   \n",
              "\n",
              "                                             Proposed Method vs.RF  \\\n",
              "Percentage Improvement university classroom                          \n",
              "0                                                            71.59   \n",
              "1                                                            68.83   \n",
              "2                                                            72.13   \n",
              "\n",
              "                                             Proposed Method vs.LSTM  \\\n",
              "Percentage Improvement university classroom                            \n",
              "0                                                              60.09   \n",
              "1                                                              60.17   \n",
              "2                                                              60.56   \n",
              "\n",
              "                                             Proposed Method vs.CEEMDAN RF  \\\n",
              "Percentage Improvement university classroom                                  \n",
              "0                                                                    34.71   \n",
              "1                                                                    36.64   \n",
              "2                                                                    36.55   \n",
              "\n",
              "                                             Proposed Method vs. CEEMDAN LSTM  \n",
              "Percentage Improvement university classroom                                    \n",
              "0                                                                        6.04  \n",
              "1                                                                        3.60  \n",
              "2                                                                        4.84  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-69a68fb2-8b11-4400-b6d7-dd9026e9f3b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Proposed Method vs.LR</th>\n",
              "      <th>Proposed Method vs.SVR</th>\n",
              "      <th>Proposed Method vs.ANN</th>\n",
              "      <th>Proposed Method vs.RF</th>\n",
              "      <th>Proposed Method vs.LSTM</th>\n",
              "      <th>Proposed Method vs.CEEMDAN RF</th>\n",
              "      <th>Proposed Method vs. CEEMDAN LSTM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Percentage Improvement university classroom</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45.43</td>\n",
              "      <td>65.65</td>\n",
              "      <td>66.66</td>\n",
              "      <td>71.59</td>\n",
              "      <td>60.09</td>\n",
              "      <td>34.71</td>\n",
              "      <td>6.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.58</td>\n",
              "      <td>66.89</td>\n",
              "      <td>65.13</td>\n",
              "      <td>68.83</td>\n",
              "      <td>60.17</td>\n",
              "      <td>36.64</td>\n",
              "      <td>3.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45.41</td>\n",
              "      <td>67.43</td>\n",
              "      <td>66.85</td>\n",
              "      <td>72.13</td>\n",
              "      <td>60.56</td>\n",
              "      <td>36.55</td>\n",
              "      <td>4.84</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69a68fb2-8b11-4400-b6d7-dd9026e9f3b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-bd654e91-756b-4378-9a74-4282888745d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd654e91-756b-4378-9a74-4282888745d5')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-bd654e91-756b-4378-9a74-4282888745d5 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69a68fb2-8b11-4400-b6d7-dd9026e9f3b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69a68fb2-8b11-4400-b6d7-dd9026e9f3b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "pMAPE_LR_vs_Proposed_univclass=((lr_univclass[0]-proposed_method_univclass[0])/lr_univclass[0])*100\n",
        "pRMSE_LR_vs_Proposed_univclass=((lr_univclass[1]-proposed_method_univclass[1])/lr_univclass[1])*100\n",
        "pMAE_LR_vs_Proposed_univclass=((lr_univclass[2]-proposed_method_univclass[2])/lr_univclass[2])*100\n",
        "\n",
        "pMAPE_SVR_vs_Proposed_univclass=((svr_univclass[0]-proposed_method_univclass[0])/svr_univclass[0])*100\n",
        "pRMSE_SVR_vs_Proposed_univclass=((svr_univclass[1]-proposed_method_univclass[1])/svr_univclass[1])*100\n",
        "pMAE_SVR_vs_Proposed_univclass=((svr_univclass[2]-proposed_method_univclass[2])/svr_univclass[2])*100\n",
        "\n",
        "pMAPE_ANN_vs_Proposed_univclass=((ann_univclass[0]-proposed_method_univclass[0])/ann_univclass[0])*100\n",
        "pRMSE_ANN_vs_Proposed_univclass=((ann_univclass[1]-proposed_method_univclass[1])/ann_univclass[1])*100\n",
        "pMAE_ANN_vs_Proposed_univclass=((ann_univclass[2]-proposed_method_univclass[2])/ann_univclass[2])*100\n",
        "\n",
        "pMAPE_RF_vs_Proposed_univclass=((rf_univclass[0]-proposed_method_univclass[0])/rf_univclass[0])*100\n",
        "pRMSE_RF_vs_Proposed_univclass=((rf_univclass[1]-proposed_method_univclass[1])/rf_univclass[1])*100\n",
        "pMAE_RF_vs_Proposed_univclass=((rf_univclass[2]-proposed_method_univclass[2])/rf_univclass[2])*100\n",
        "\n",
        "pMAPE_LSTM_vs_Proposed_univclass=((lstm_univclass[0]-proposed_method_univclass[0])/lstm_univclass[0])*100\n",
        "pRMSE_LSTM_vs_Proposed_univclass=((lstm_univclass[1]-proposed_method_univclass[1])/lstm_univclass[1])*100\n",
        "pMAE_LSTM_vs_Proposed_univclass=((lstm_univclass[2]-proposed_method_univclass[2])/lstm_univclass[2])*100\n",
        "\n",
        "pMAPE_ceemdan_rf_vs_Proposed_univclass=((ceemdan_rf_univclass[0]-proposed_method_univclass[0])/ceemdan_rf_univclass[0])*100\n",
        "pRMSE_ceemdan_rf_vs_Proposed_univclass=((ceemdan_rf_univclass[1]-proposed_method_univclass[1])/ceemdan_rf_univclass[1])*100\n",
        "pMAE_ceemdan_rf_vs_Proposed_univclass=((ceemdan_rf_univclass[2]-proposed_method_univclass[2])/ceemdan_rf_univclass[2])*100\n",
        "\n",
        "\n",
        "pMAPE_ceemdan_lstm_vs_Proposed_univclass=((ceemdan_lstm_univclass[0]-proposed_method_univclass[0])/ceemdan_lstm_univclass[0])*100\n",
        "pRMSE_ceemdan_lstm_vs_Proposed_univclass=((ceemdan_lstm_univclass[1]-proposed_method_univclass[1])/ceemdan_lstm_univclass[1])*100\n",
        "pMAE_ceemdan_lstm_vs_Proposed_univclass=((ceemdan_lstm_univclass[2]-proposed_method_univclass[2])/ceemdan_lstm_univclass[2])*100\n",
        "\n",
        "\n",
        "df_PI_univclass=[[pMAPE_LR_vs_Proposed_univclass,pMAPE_SVR_vs_Proposed_univclass,pMAPE_ANN_vs_Proposed_univclass,\n",
        "                pMAPE_RF_vs_Proposed_univclass,pMAPE_LSTM_vs_Proposed_univclass,pMAPE_ceemdan_rf_vs_Proposed_univclass,\n",
        "                pMAPE_ceemdan_lstm_vs_Proposed_univclass],\n",
        "                [pRMSE_LR_vs_Proposed_univclass,pRMSE_SVR_vs_Proposed_univclass,pRMSE_ANN_vs_Proposed_univclass,\n",
        "                pRMSE_RF_vs_Proposed_univclass,pRMSE_LSTM_vs_Proposed_univclass,pRMSE_ceemdan_rf_vs_Proposed_univclass,\n",
        "                pRMSE_ceemdan_lstm_vs_Proposed_univclass],\n",
        "                [pMAE_LR_vs_Proposed_univclass,pMAE_SVR_vs_Proposed_univclass,pMAE_ANN_vs_Proposed_univclass,\n",
        "                pMAE_RF_vs_Proposed_univclass,pMAE_LSTM_vs_Proposed_univclass,pMAE_ceemdan_rf_vs_Proposed_univclass,\n",
        "                pMAE_ceemdan_lstm_vs_Proposed_univclass]]\n",
        "\n",
        "PI_univclass=pd.DataFrame(df_PI_univclass, columns=[\"Proposed Method vs.LR\", \"Proposed Method vs.SVR\",\" Proposed Method vs.ANN\",\n",
        "                                      \"Proposed Method vs.RF\",\"Proposed Method vs.LSTM\",\"Proposed Method vs.CEEMDAN RF\",\n",
        "                                      \"Proposed Method vs. CEEMDAN LSTM\"])\n",
        "PI_univclass= PI_univclass.round(decimals = 2)\n",
        "PI_univclass.set_axis(['MAPE(%)', 'RMSE','MAE'], axis='index')\n",
        "PI_univclass.style.set_caption(\"Percentage Improvement-University Classroom Building\")\n",
        "index = PI_univclass.index\n",
        "index.name = \"Percentage Improvement university classroom\"\n",
        "PI_univclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6DvtpYMxZ5XA"
      },
      "outputs": [],
      "source": [
        "#export table to png\n",
        "#dfi.export(PI_univclass,\"PI_univclass_table.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYx8pbLfZ5XA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viVTNdGHZ5XB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}