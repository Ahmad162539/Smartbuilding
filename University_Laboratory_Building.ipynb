{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/Smartbuilding/blob/main/University_Laboratory_Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXVuCV4KWRwR"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wj509FW4WRwT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url_univlab= 'https://raw.githubusercontent.com/Ahmad162539/Smartbuilding/main/data%20of%20UnivLab_Christy.csv'\n",
        "univlab= pd.read_csv(url_univlab)\n",
        "data_univlab= univlab[(univlab['timestamp'] > '2015-03-01') & (univlab['timestamp'] < '2015-06-01')]\n",
        "dfs_univlab=data_univlab['energy']\n",
        "datas_univlab=pd.DataFrame(dfs_univlab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSUwafFxWRwU"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YG3A5PcIWRwU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter('ignore')\n",
        "\n",
        "import numpy\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn import metrics\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install EMD-signal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDLWcccTWpet",
        "outputId": "9893c149-9fc0-42d9-bce7-291e1d16b511"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting EMD-signal\n",
            "  Downloading EMD_signal-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.10.1)\n",
            "Collecting pathos>=0.2.1 (from EMD-signal)\n",
            "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.* (from EMD-signal)\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ppft>=1.7.6.6 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.6 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.2 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.14 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, ppft, pox, dill, multiprocess, pathos, EMD-signal\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "Successfully installed EMD-signal-1.5.1 dill-0.3.6 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 tqdm-4.64.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyEMD import CEEMDAN"
      ],
      "metadata": {
        "id": "dXP-jnBEWvh1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dataframe_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1VXfIBIWzGc",
        "outputId": "da7588b6-0d38-448e-e1e4-acc55f745a6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataframe_image\n",
            "  Downloading dataframe_image-0.1.11-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (1.5.3)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (6.5.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (8.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (23.1)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (0.8.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from dataframe_image) (4.11.2)\n",
            "Collecting cssutils (from dataframe_image)\n",
            "  Downloading cssutils-2.7.1-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2image (from dataframe_image)\n",
            "  Downloading html2image-2.0.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (2.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (0.8.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.9.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (1.5.0)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (2.14.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (1.2.1)\n",
            "Requirement already satisfied: traitlets>=5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->dataframe_image) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->dataframe_image) (1.22.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dataframe_image) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->dataframe_image) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dataframe_image) (3.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert>=5->dataframe_image) (3.8.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert>=5->dataframe_image) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert>=5->dataframe_image) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert>=5->dataframe_image) (4.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24->dataframe_image) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->dataframe_image) (0.5.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert>=5->dataframe_image) (0.19.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (23.2.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (6.3.1)\n",
            "Installing collected packages: html2image, cssutils, dataframe_image\n",
            "Successfully installed cssutils-2.7.1 dataframe_image-0.1.11 html2image-2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dataframe_image as dfi"
      ],
      "metadata": {
        "id": "jS8tFe1PW2qc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1JRsxtXWRwU"
      },
      "source": [
        "## Import all functions from another notebook for building prediction methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qI1OSOe5WRwU"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "#Parameters Settings\n",
        "\n",
        "max_features=8 # the feature number of each node is set to 8, as it is suggested to be one-third of the feature's number (Lahouar and Slama,2017)\n",
        "lr=0.001 #learning rate LSTM as recommended in (Kingma and Ba, 2014)\n",
        "optimizer='Adam' #Adam is used as the optimizer for LSTM as it is computationally efficient (Dubey, Ashutosh Kumar, et al,2021)\n",
        "neuron=64\n",
        "epoch=100 #(Jorges et al, 2021)\n",
        "batch_size=64 #(Kandel et al,2020)\n",
        "hours=24 #in this study, to predict one hour ahead predicton, we use input from the previous 24 hour energy consumption\n",
        "data_partition=0.8 #in this study, we divided the data into 80% of data as training data and 20% of the data as testing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PyEMD import CEEMDAN\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "### import the libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "def percentage_error(actual, predicted):\n",
        "    res = numpy.empty(actual.shape)\n",
        "    for j in range(actual.shape[0]):\n",
        "        if actual[j] != 0:\n",
        "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
        "        else:\n",
        "            res[j] = predicted[j] / np.mean(actual)\n",
        "    return res\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n",
        "\n",
        "\n",
        "\n",
        "# In[25]:\n",
        "\n",
        "\n",
        "def lr_model(datass,look_back,data_partition):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "    import tensorflow as tf\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "\n",
        "    grid = LinearRegression()\n",
        "\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_lr= grid.predict(X)\n",
        "    y_pred_test_lr= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_lr=pd.DataFrame(y_pred_train_lr)\n",
        "    y_pred_test_lr=pd.DataFrame(y_pred_test_lr)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)\n",
        "    y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)\n",
        "    y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_lr)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_lr))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_lr)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[26]:\n",
        "\n",
        "\n",
        "def svr_model(datass,look_back,data_partition):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "    from sklearn.svm import SVR\n",
        "\n",
        "    grid = SVR()\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_svr= grid.predict(X)\n",
        "    y_pred_test_svr= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_svr=pd.DataFrame(y_pred_train_svr)\n",
        "    y_pred_test_svr=pd.DataFrame(y_pred_test_svr)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)\n",
        "    y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_svr=pd.DataFrame(y_pred_test1_svr)\n",
        "    y_pred_train1_svr=pd.DataFrame(y_pred_train1_svr)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_svr)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_svr))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_svr)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[27]:\n",
        "\n",
        "\n",
        "\n",
        "def ann_model(datass,look_back,data_partition):\n",
        "\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    import numpy\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "    from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "    model= MLPRegressor(random_state=1,activation='tanh').fit(X,y)\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "    # make predictions\n",
        "    y_pred_train = model.predict(X)\n",
        "    y_pred_test = model.predict(X1)\n",
        "    y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "\n",
        "    y_pred_test=pd.DataFrame(y_pred_test)\n",
        "    y1=pd.DataFrame(y1)\n",
        "\n",
        "    y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[28]:\n",
        "\n",
        "\n",
        "def rf_model(datass,look_back,data_partition,max_features):\n",
        "\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "    grid = RandomForestRegressor(max_features=max_features)\n",
        "    grid.fit(X,y)\n",
        "    y_pred_train_rf= grid.predict(X)\n",
        "    y_pred_test_rf= grid.predict(X1)\n",
        "\n",
        "    y_pred_train_rf=pd.DataFrame(y_pred_train_rf)\n",
        "    y_pred_test_rf=pd.DataFrame(y_pred_test_rf)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "\n",
        "    y_pred_test1_rf= sc_y.inverse_transform (y_pred_test_rf)\n",
        "    y_pred_train1_rf=sc_y.inverse_transform (y_pred_train_rf)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "    y_pred_test1_rf=pd.DataFrame(y_pred_test1_rf)\n",
        "    y_pred_train1_rf=pd.DataFrame(y_pred_train1_rf)\n",
        "\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1_rf)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_rf))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1_rf)\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "\n",
        "def lstm_model(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "    datasets=datass.values\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "    trainX1 = numpy.reshape(X, (X.shape[0],1,X.shape[1]))\n",
        "    testX1 = numpy.reshape(X1, (X1.shape[0],1,X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    import os\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers.core import Dense, Dropout, Activation\n",
        "    from keras.layers import LSTM\n",
        "\n",
        "\n",
        "    neuron=neuron\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units = neuron,input_shape=(trainX1.shape[1], trainX1.shape[2])))\n",
        "    model.add(Dense(1))\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(loss='mse',optimizer=optimizer)\n",
        "#    model.summary()\n",
        "\n",
        "\n",
        "  # Fitting the RNN to the Training s\n",
        "    model.fit(trainX1, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "  # make predictions\n",
        "    y_pred_train = model.predict(trainX1)\n",
        "    y_pred_test = model.predict(testX1)\n",
        "    y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "\n",
        "    y_pred_test=pd.DataFrame(y_pred_test)\n",
        "    y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "    y1=pd.DataFrame(y1)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "    from sklearn import metrics\n",
        "\n",
        "    mape=mean_absolute_percentage_error(y_test,y_pred_test1)\n",
        "    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))\n",
        "    mae=metrics.mean_absolute_error(y_test,y_pred_test1)\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "###################################################hybrid based ceemdan####################################################\n",
        "def hybrid_ceemdan_rf(datass,look_back,data_partition,max_features):\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    for col in data_imf:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[col])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "        grid = RandomForestRegressor(max_features=max_features)\n",
        "        grid.fit(X,y)\n",
        "        y_pred_train= grid.predict(X)\n",
        "        y_pred_test= grid.predict(X1)\n",
        "\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "\n",
        "def hybrid_ceemdan_lstm(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "\n",
        "\n",
        "    from PyEMD import CEEMDAN\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    for col in data_imf:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[col])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers.core import Dense, Dropout, Activation\n",
        "        from keras.layers import LSTM\n",
        "\n",
        "\n",
        "        neuron=neuron\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "        model.add(Dense(1))\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        model.compile(loss='mse',optimizer=optimizer)\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "        # Fitting the RNN to the Training set\n",
        "        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "\n",
        "        # make predictions\n",
        "        y_pred_train = model.predict(trainX)\n",
        "        y_pred_test = model.predict(testX)\n",
        "\n",
        "        # make predictions\n",
        "\n",
        "        y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "        y_pred_train= numpy.array(y_pred_train).ravel()\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "    return mape,rmse,mae\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "def proposed_method(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):\n",
        "\n",
        "    from PyEMD import CEEMDAN\n",
        "\n",
        "\n",
        "    dfs=datass\n",
        "    s = dfs.values\n",
        "\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "\n",
        "    IMFs = emd(s)\n",
        "\n",
        "\n",
        "    full_imf=pd.DataFrame(IMFs)\n",
        "    data_imf=full_imf.T\n",
        "\n",
        "\n",
        "\n",
        "    pred_test=[]\n",
        "    test_ori=[]\n",
        "    pred_train=[]\n",
        "    train_ori=[]\n",
        "\n",
        "\n",
        "    n_imf=len(data_imf.columns)\n",
        "\n",
        "    k=list(range(1,n_imf))\n",
        "    m=[0]\n",
        "\n",
        "\n",
        "    for i in m:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[i])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "        grid = RandomForestRegressor(max_features=max_features)\n",
        "        grid.fit(X,y)\n",
        "        y_pred_train= grid.predict(X)\n",
        "        y_pred_test= grid.predict(X1)\n",
        "\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in k:\n",
        "\n",
        "        datasetss2=pd.DataFrame(data_imf[i])\n",
        "        datasets=datasetss2.values\n",
        "        train_size = int(len(datasets) * data_partition)\n",
        "        test_size = len(datasets) - train_size\n",
        "        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "        X_train=pd.DataFrame(trainX)\n",
        "        Y_train=pd.DataFrame(trainY)\n",
        "        X_test=pd.DataFrame(testX)\n",
        "        Y_test=pd.DataFrame(testY)\n",
        "        sc_X = StandardScaler()\n",
        "        sc_y = StandardScaler()\n",
        "        X= sc_X.fit_transform(X_train)\n",
        "        y= sc_y.fit_transform(Y_train)\n",
        "        X1= sc_X.fit_transform(X_test)\n",
        "        y1= sc_y.fit_transform(Y_test)\n",
        "        y=y.ravel()\n",
        "        y1=y1.ravel()\n",
        "\n",
        "        import numpy\n",
        "\n",
        "        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "        import tensorflow as tf\n",
        "        tf.random.set_seed(1234)\n",
        "\n",
        "\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers.core import Dense, Dropout, Activation\n",
        "        from keras.layers import LSTM\n",
        "\n",
        "        neuron=neuron\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "        model.add(Dense(1))\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        model.compile(loss='mse',optimizer=optimizer)\n",
        "\n",
        "\n",
        "        numpy.random.seed(1234)\n",
        "\n",
        "\n",
        "     # Fitting the RNN to the Training set\n",
        "        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)\n",
        "\n",
        "\n",
        "        # make predictions\n",
        "        y_pred_train = model.predict(trainX)\n",
        "        y_pred_test = model.predict(testX)\n",
        "\n",
        "        # make predictions\n",
        "\n",
        "\n",
        "        y_pred_test= numpy.array(y_pred_test).ravel()\n",
        "        y_pred_test=pd.DataFrame(y_pred_test)\n",
        "        y1=pd.DataFrame(y1)\n",
        "        y=pd.DataFrame(y)\n",
        "        y_pred_train= numpy.array(y_pred_train).ravel()\n",
        "        y_pred_train=pd.DataFrame(y_pred_train)\n",
        "\n",
        "\n",
        "        y_test= sc_y.inverse_transform (y1)\n",
        "        y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "        y_pred_test1= sc_y.inverse_transform (y_pred_test)\n",
        "        y_pred_train1= sc_y.inverse_transform (y_pred_train)\n",
        "\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "    result_pred_test= pd.DataFrame.from_records(pred_test)\n",
        "    result_pred_train= pd.DataFrame.from_records(pred_train)\n",
        "\n",
        "\n",
        "    a=result_pred_test.sum(axis = 0, skipna = True)\n",
        "    b=result_pred_train.sum(axis = 0, skipna = True)\n",
        "\n",
        "\n",
        "    dataframe=pd.DataFrame(dfs)\n",
        "    dataset=dataframe.values\n",
        "\n",
        "    train_size = int(len(dataset) * data_partition)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train=pd.DataFrame(trainX)\n",
        "    Y_train=pd.DataFrame(trainY)\n",
        "    X_test=pd.DataFrame(testX)\n",
        "    Y_test=pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "    X= sc_X.fit_transform(X_train)\n",
        "    y= sc_y.fit_transform(Y_train)\n",
        "    X1= sc_X.fit_transform(X_test)\n",
        "    y1= sc_y.fit_transform(Y_test)\n",
        "    y=y.ravel()\n",
        "    y1=y1.ravel()\n",
        "\n",
        "\n",
        "    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))\n",
        "\n",
        "    numpy.random.seed(1234)\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    y1=pd.DataFrame(y1)\n",
        "    y=pd.DataFrame(y)\n",
        "    y_test= sc_y.inverse_transform (y1)\n",
        "    y_train= sc_y.inverse_transform (y)\n",
        "\n",
        "\n",
        "    a= pd.DataFrame(a)\n",
        "    y_test= pd.DataFrame(y_test)\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "\n",
        "   #summarize the fit of the model\n",
        "    mape=mean_absolute_percentage_error(y_test,a)\n",
        "    rmse= sqrt(mean_squared_error(y_test,a))\n",
        "    mae=metrics.mean_absolute_error(y_test,a)\n",
        "\n",
        "    return mape,rmse,mae,a,y_test\n"
      ],
      "metadata": {
        "id": "XfBCxnbBXA5N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdVHxZABWRwU"
      },
      "source": [
        "## Import parameter settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLhu66j8WRwV"
      },
      "source": [
        "## Run the experiments\n",
        "### Run this following cell will train and test the proposed method and other benchmark methods on University Laboratory Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB5xQPPsWRwV",
        "outputId": "aa2a4593-3aa3-4ffa-cec7-c51eca067da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 0.3701629638671875 seconds - Linear Regression- univlab ---\n",
            "--- 1.1945862770080566 seconds - Support Vector Regression- univlab ---\n",
            "--- 15.744020462036133 seconds - ANN- univlab ---\n",
            "--- 2.368340492248535 seconds - Random Forest- univlab ---\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "--- 17.50617289543152 seconds - lstm- univlab ---\n",
            "--- 31.127997636795044 seconds - ceemdan_rf- univlab ---\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "--- 118.58984112739563 seconds - ceemdan_lstm- univlab ---\n",
            "53/53 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "53/53 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "53/53 [==============================] - 1s 3ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 1s 2ms/step\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "--- 108.96115708351135 seconds - proposed_method- univlab ---\n"
          ]
        }
      ],
      "source": [
        "#Linear Regression\n",
        "\n",
        "start_time = time.time()\n",
        "lr_univlab=lr_model(datas_univlab,hours,data_partition)\n",
        "lr_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - Linear Regression- univlab ---\" % (lr_time_univlab))\n",
        "\n",
        "#Support Vector Regression\n",
        "start_time = time.time()\n",
        "svr_univlab=svr_model(datas_univlab,hours,data_partition)\n",
        "svr_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - Support Vector Regression- univlab ---\" % (svr_time_univlab))\n",
        "\n",
        "\n",
        "#ANN\n",
        "start_time = time.time()\n",
        "ann_univlab=ann_model(datas_univlab,hours,data_partition)\n",
        "ann_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - ANN- univlab ---\" % (ann_time_univlab))\n",
        "\n",
        "#random forest\n",
        "start_time = time.time()\n",
        "rf_univlab=rf_model(datas_univlab,hours,data_partition,max_features)\n",
        "rf_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - Random Forest- univlab ---\" % (rf_time_univlab))\n",
        "\n",
        "#LSTM\n",
        "start_time = time.time()\n",
        "lstm_univlab=lstm_model(datas_univlab,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "lstm_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - lstm- univlab ---\" % (lstm_time_univlab))\n",
        "\n",
        "\n",
        "#CEEMDAN RF\n",
        "start_time = time.time()\n",
        "ceemdan_rf_univlab=hybrid_ceemdan_rf(dfs_univlab,hours,data_partition,max_features)\n",
        "ceemdan_rf_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - ceemdan_rf- univlab ---\" % (ceemdan_rf_time_univlab))\n",
        "\n",
        "#CEEMDAN LSTM\n",
        "start_time = time.time()\n",
        "ceemdan_lstm_univlab=hybrid_ceemdan_lstm(dfs_univlab,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "ceemdan_lstm_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - ceemdan_lstm- univlab ---\" % (ceemdan_lstm_time_univlab))\n",
        "\n",
        "\n",
        "#proposed method\n",
        "start_time = time.time()\n",
        "proposed_method_univlab=proposed_method(dfs_univlab,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)\n",
        "proposed_method_time_univlab=time.time() - start_time\n",
        "print(\"--- %s seconds - proposed_method- univlab ---\" % (proposed_method_time_univlab))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lMk8X48WRwW"
      },
      "source": [
        "## Summarize of experimental results with running time\n",
        "### Run this following cell will summarize the result and generate output used in Section 4.4 (Table 3) for University Laboratory dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8Uyuwqg0WRwW",
        "outputId": "432f2082-ebdb-48fe-e055-3b6f16e6ae1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     LR       SVR        ANN        RF  \\\n",
              "university laboratory results                                            \n",
              "0                              5.858858  6.419207   6.134858  6.300708   \n",
              "1                              2.579903  2.706899   2.658628  2.728669   \n",
              "2                              1.864822  2.093199   2.004848  2.057561   \n",
              "0                              0.370163  1.194586  15.744020  2.368340   \n",
              "\n",
              "                                    LSTM  CEEMDAN RF  CEEMDAN LSTM  \\\n",
              "university laboratory results                                        \n",
              "0                               6.464001    3.526199      3.575848   \n",
              "1                               2.694062    1.461045      1.432516   \n",
              "2                               2.085680    1.118182      1.135480   \n",
              "0                              17.506173   31.127998    118.589841   \n",
              "\n",
              "                               Proposed Method  \n",
              "university laboratory results                   \n",
              "0                                     3.140996  \n",
              "1                                     1.268738  \n",
              "2                                     0.999068  \n",
              "0                                   108.961157  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-6f7a7edf-1664-4cb4-ab74-4b4f4998822f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LR</th>\n",
              "      <th>SVR</th>\n",
              "      <th>ANN</th>\n",
              "      <th>RF</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>CEEMDAN RF</th>\n",
              "      <th>CEEMDAN LSTM</th>\n",
              "      <th>Proposed Method</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>university laboratory results</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.858858</td>\n",
              "      <td>6.419207</td>\n",
              "      <td>6.134858</td>\n",
              "      <td>6.300708</td>\n",
              "      <td>6.464001</td>\n",
              "      <td>3.526199</td>\n",
              "      <td>3.575848</td>\n",
              "      <td>3.140996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.579903</td>\n",
              "      <td>2.706899</td>\n",
              "      <td>2.658628</td>\n",
              "      <td>2.728669</td>\n",
              "      <td>2.694062</td>\n",
              "      <td>1.461045</td>\n",
              "      <td>1.432516</td>\n",
              "      <td>1.268738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.864822</td>\n",
              "      <td>2.093199</td>\n",
              "      <td>2.004848</td>\n",
              "      <td>2.057561</td>\n",
              "      <td>2.085680</td>\n",
              "      <td>1.118182</td>\n",
              "      <td>1.135480</td>\n",
              "      <td>0.999068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.370163</td>\n",
              "      <td>1.194586</td>\n",
              "      <td>15.744020</td>\n",
              "      <td>2.368340</td>\n",
              "      <td>17.506173</td>\n",
              "      <td>31.127998</td>\n",
              "      <td>118.589841</td>\n",
              "      <td>108.961157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f7a7edf-1664-4cb4-ab74-4b4f4998822f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f992dbf9-5f09-465a-ad2e-7dc7eb64c39d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f992dbf9-5f09-465a-ad2e-7dc7eb64c39d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f992dbf9-5f09-465a-ad2e-7dc7eb64c39d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f7a7edf-1664-4cb4-ab74-4b4f4998822f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f7a7edf-1664-4cb4-ab74-4b4f4998822f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "running_time_univlab=pd.DataFrame([lr_time_univlab,svr_time_univlab,ann_time_univlab,\n",
        "                                   rf_time_univlab,lstm_time_univlab,ceemdan_rf_time_univlab,\n",
        "                                   ceemdan_lstm_time_univlab,proposed_method_time_univlab])\n",
        "running_time_univlab=running_time_univlab.T\n",
        "running_time_univlab.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method']\n",
        "\n",
        "proposed_method_univlab_df=proposed_method_univlab[0:3]\n",
        "result_univlab=pd.DataFrame([lr_univlab,svr_univlab,ann_univlab,rf_univlab,lstm_univlab,ceemdan_rf_univlab,\n",
        "                    ceemdan_lstm_univlab,proposed_method_univlab_df])\n",
        "result_univlab=result_univlab.T\n",
        "result_univlab.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method']\n",
        "univlab_summary=pd.concat([result_univlab,running_time_univlab],axis=0)\n",
        "\n",
        "univlab_summary.set_axis(['MAPE(%)', 'RMSE','MAE','running time (s)'], axis='index')\n",
        "\n",
        "univlab_summary.style.set_caption(\"University Laboratory Results\")\n",
        "index = univlab_summary.index\n",
        "index.name = \"university laboratory results\"\n",
        "univlab_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dalG2B_5WRwW"
      },
      "outputs": [],
      "source": [
        "#export table to png\n",
        "#dfi.export(univlab_summary,\"univlab_summary_table.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDS52CeTWRwW"
      },
      "source": [
        "## Calculate percentage improvement\n",
        "### Run this following cell will calculate percentage improvement and generate output used in Section 4.4 (Table 4) for University Laboratory dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "X-AY1tjgWRwX",
        "outputId": "b760b7b4-a3aa-4822-da90-1b16854786c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Proposed Method vs.LR  \\\n",
              "Percentage Improvement university laboratory                          \n",
              "0                                                             46.39   \n",
              "1                                                             50.82   \n",
              "2                                                             46.43   \n",
              "\n",
              "                                              Proposed Method vs.SVR  \\\n",
              "Percentage Improvement university laboratory                           \n",
              "0                                                              51.07   \n",
              "1                                                              53.13   \n",
              "2                                                              52.27   \n",
              "\n",
              "                                               Proposed Method vs.ANN  \\\n",
              "Percentage Improvement university laboratory                            \n",
              "0                                                               48.80   \n",
              "1                                                               52.28   \n",
              "2                                                               50.17   \n",
              "\n",
              "                                              Proposed Method vs.RF  \\\n",
              "Percentage Improvement university laboratory                          \n",
              "0                                                             50.15   \n",
              "1                                                             53.50   \n",
              "2                                                             51.44   \n",
              "\n",
              "                                              Proposed Method vs.LSTM  \\\n",
              "Percentage Improvement university laboratory                            \n",
              "0                                                               51.41   \n",
              "1                                                               52.91   \n",
              "2                                                               52.10   \n",
              "\n",
              "                                              Proposed Method vs.CEEMDAN RF  \\\n",
              "Percentage Improvement university laboratory                                  \n",
              "0                                                                     10.92   \n",
              "1                                                                     13.16   \n",
              "2                                                                     10.65   \n",
              "\n",
              "                                              Proposed Method vs. CEEMDAN LSTM  \n",
              "Percentage Improvement university laboratory                                    \n",
              "0                                                                        12.16  \n",
              "1                                                                        11.43  \n",
              "2                                                                        12.01  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-13745a2f-920c-4e84-bca9-88d6a2f3ed16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Proposed Method vs.LR</th>\n",
              "      <th>Proposed Method vs.SVR</th>\n",
              "      <th>Proposed Method vs.ANN</th>\n",
              "      <th>Proposed Method vs.RF</th>\n",
              "      <th>Proposed Method vs.LSTM</th>\n",
              "      <th>Proposed Method vs.CEEMDAN RF</th>\n",
              "      <th>Proposed Method vs. CEEMDAN LSTM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Percentage Improvement university laboratory</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46.39</td>\n",
              "      <td>51.07</td>\n",
              "      <td>48.80</td>\n",
              "      <td>50.15</td>\n",
              "      <td>51.41</td>\n",
              "      <td>10.92</td>\n",
              "      <td>12.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.82</td>\n",
              "      <td>53.13</td>\n",
              "      <td>52.28</td>\n",
              "      <td>53.50</td>\n",
              "      <td>52.91</td>\n",
              "      <td>13.16</td>\n",
              "      <td>11.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46.43</td>\n",
              "      <td>52.27</td>\n",
              "      <td>50.17</td>\n",
              "      <td>51.44</td>\n",
              "      <td>52.10</td>\n",
              "      <td>10.65</td>\n",
              "      <td>12.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13745a2f-920c-4e84-bca9-88d6a2f3ed16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-7d44e637-254e-4b65-a96d-346ee97aeba9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d44e637-254e-4b65-a96d-346ee97aeba9')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-7d44e637-254e-4b65-a96d-346ee97aeba9 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13745a2f-920c-4e84-bca9-88d6a2f3ed16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13745a2f-920c-4e84-bca9-88d6a2f3ed16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "pMAPE_LR_vs_Proposed_univlab=((lr_univlab[0]-proposed_method_univlab[0])/lr_univlab[0])*100\n",
        "pRMSE_LR_vs_Proposed_univlab=((lr_univlab[1]-proposed_method_univlab[1])/lr_univlab[1])*100\n",
        "pMAE_LR_vs_Proposed_univlab=((lr_univlab[2]-proposed_method_univlab[2])/lr_univlab[2])*100\n",
        "\n",
        "pMAPE_SVR_vs_Proposed_univlab=((svr_univlab[0]-proposed_method_univlab[0])/svr_univlab[0])*100\n",
        "pRMSE_SVR_vs_Proposed_univlab=((svr_univlab[1]-proposed_method_univlab[1])/svr_univlab[1])*100\n",
        "pMAE_SVR_vs_Proposed_univlab=((svr_univlab[2]-proposed_method_univlab[2])/svr_univlab[2])*100\n",
        "\n",
        "pMAPE_ANN_vs_Proposed_univlab=((ann_univlab[0]-proposed_method_univlab[0])/ann_univlab[0])*100\n",
        "pRMSE_ANN_vs_Proposed_univlab=((ann_univlab[1]-proposed_method_univlab[1])/ann_univlab[1])*100\n",
        "pMAE_ANN_vs_Proposed_univlab=((ann_univlab[2]-proposed_method_univlab[2])/ann_univlab[2])*100\n",
        "\n",
        "pMAPE_RF_vs_Proposed_univlab=((rf_univlab[0]-proposed_method_univlab[0])/rf_univlab[0])*100\n",
        "pRMSE_RF_vs_Proposed_univlab=((rf_univlab[1]-proposed_method_univlab[1])/rf_univlab[1])*100\n",
        "pMAE_RF_vs_Proposed_univlab=((rf_univlab[2]-proposed_method_univlab[2])/rf_univlab[2])*100\n",
        "\n",
        "pMAPE_LSTM_vs_Proposed_univlab=((lstm_univlab[0]-proposed_method_univlab[0])/lstm_univlab[0])*100\n",
        "pRMSE_LSTM_vs_Proposed_univlab=((lstm_univlab[1]-proposed_method_univlab[1])/lstm_univlab[1])*100\n",
        "pMAE_LSTM_vs_Proposed_univlab=((lstm_univlab[2]-proposed_method_univlab[2])/lstm_univlab[2])*100\n",
        "\n",
        "pMAPE_ceemdan_rf_vs_Proposed_univlab=((ceemdan_rf_univlab[0]-proposed_method_univlab[0])/ceemdan_rf_univlab[0])*100\n",
        "pRMSE_ceemdan_rf_vs_Proposed_univlab=((ceemdan_rf_univlab[1]-proposed_method_univlab[1])/ceemdan_rf_univlab[1])*100\n",
        "pMAE_ceemdan_rf_vs_Proposed_univlab=((ceemdan_rf_univlab[2]-proposed_method_univlab[2])/ceemdan_rf_univlab[2])*100\n",
        "\n",
        "\n",
        "pMAPE_ceemdan_lstm_vs_Proposed_univlab=((ceemdan_lstm_univlab[0]-proposed_method_univlab[0])/ceemdan_lstm_univlab[0])*100\n",
        "pRMSE_ceemdan_lstm_vs_Proposed_univlab=((ceemdan_lstm_univlab[1]-proposed_method_univlab[1])/ceemdan_lstm_univlab[1])*100\n",
        "pMAE_ceemdan_lstm_vs_Proposed_univlab=((ceemdan_lstm_univlab[2]-proposed_method_univlab[2])/ceemdan_lstm_univlab[2])*100\n",
        "\n",
        "\n",
        "df_PI_univlab=[[pMAPE_LR_vs_Proposed_univlab,pMAPE_SVR_vs_Proposed_univlab,pMAPE_ANN_vs_Proposed_univlab,\n",
        "                pMAPE_RF_vs_Proposed_univlab,pMAPE_LSTM_vs_Proposed_univlab,pMAPE_ceemdan_rf_vs_Proposed_univlab,\n",
        "                pMAPE_ceemdan_lstm_vs_Proposed_univlab],\n",
        "                [pRMSE_LR_vs_Proposed_univlab,pRMSE_SVR_vs_Proposed_univlab,pRMSE_ANN_vs_Proposed_univlab,\n",
        "                pRMSE_RF_vs_Proposed_univlab,pRMSE_LSTM_vs_Proposed_univlab,pRMSE_ceemdan_rf_vs_Proposed_univlab,\n",
        "                pRMSE_ceemdan_lstm_vs_Proposed_univlab],\n",
        "                [pMAE_LR_vs_Proposed_univlab,pMAE_SVR_vs_Proposed_univlab,pMAE_ANN_vs_Proposed_univlab,\n",
        "                pMAE_RF_vs_Proposed_univlab,pMAE_LSTM_vs_Proposed_univlab,pMAE_ceemdan_rf_vs_Proposed_univlab,\n",
        "                pMAE_ceemdan_lstm_vs_Proposed_univlab]]\n",
        "\n",
        "PI_univlab=pd.DataFrame(df_PI_univlab, columns=[\"Proposed Method vs.LR\", \"Proposed Method vs.SVR\",\" Proposed Method vs.ANN\",\n",
        "                                      \"Proposed Method vs.RF\",\"Proposed Method vs.LSTM\",\"Proposed Method vs.CEEMDAN RF\",\n",
        "                                      \"Proposed Method vs. CEEMDAN LSTM\"])\n",
        "PI_univlab= PI_univlab.round(decimals = 2)\n",
        "PI_univlab.set_axis(['MAPE(%)', 'RMSE','MAE'], axis='index')\n",
        "PI_univlab.style.set_caption(\"Percentage Improvement-University Laboratory Building\")\n",
        "index = PI_univlab.index\n",
        "index.name = \"Percentage Improvement university laboratory\"\n",
        "PI_univlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX4r9uu6WRwX"
      },
      "outputs": [],
      "source": [
        "#export table to png\n",
        "#dfi.export(PI_univlab,\"PI_univlab_table.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0DKE_9lWRwX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}